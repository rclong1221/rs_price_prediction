{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prediction\n",
    "\n",
    "### Stacked Model: XGB + LGBM => Elastic Net Meta Regressor\n",
    "\n",
    "The best performing model in terms of fit was a stacked ensemble, bearing an R2 score of approximately 0.9125. It is important to restate the results of the learning curves explored for each model -- though the R2 scores are quite high, there model tuning did not affect the overall convergence of each respective algorithm (XGB, LGBM), indicating that more data is needed to both improve the fit, and allow the validation and training errors to converge to a better value.\n",
    "\n",
    "This section entails benchmarking of the stacked ensemble with regards to prediction time, and final analysis of error metrics for the testing phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritch_000\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso, ElasticNet)\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import warnings\n",
    "import os\n",
    "import timeit\n",
    "import time\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "SEED=42\n",
    "CV_FOLDS=10\n",
    "\n",
    "kc_data = pd.read_csv('./data/ci_i5_ap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_data = kc_data.drop(['id', 'date'], axis=1)\n",
    "kc_data.head()\n",
    "# kc_data['price'] = np.log(kc_data['price'])\n",
    "kc_train, kc_test, train_Y, test_Y = train_test_split(\n",
    "    kc_data, kc_data['price'], \n",
    "    test_size=0, \n",
    "    random_state=SEED\n",
    ")\n",
    "kc_train = kc_train.drop('price', axis=1)\n",
    "kc_test = kc_test.drop('price', axis=1)\n",
    "scaler = StandardScaler()\n",
    "kc_train = scaler.fit_transform(kc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBRegressor(\n",
    "    min_child_weight=9, \n",
    "    max_depth=1, \n",
    "    objective='reg:linear',\n",
    "    learning_rate=0.01, \n",
    "    seed=SEED, \n",
    "    n_estimators=2750, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "svr = svm.SVR(degree=1, C=0.03)\n",
    "\n",
    "dtr = DecisionTreeRegressor(\n",
    "    max_depth=12, \n",
    "    min_samples_leaf=11,\n",
    "    min_samples_split=2,\n",
    "    random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "lin_reg = LinearRegression()\n",
    "meta_reg_elastic = ElasticNet(\n",
    "#     alpha=0.0095, \n",
    "#     l1_ratio=0, \n",
    "#     tol=0.00001, \n",
    "    random_state=SEED\n",
    ")\n",
    "stacked_reg = StackingRegressor(regressors=[dtr, svr, gbm], meta_regressor = meta_reg_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Dataframes to save results\n",
    "gbm_df = pd.DataFrame(columns=[['avg_pred', 'single_pred', 'rmse', 'mae', 'logerror']])\n",
    "lgbm_df = pd.DataFrame(columns=[['avg_pred', 'single_pred', 'rmse', 'mae', 'logerror']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.34797528024686236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv = cross_val_score(stacked_reg, kc_train, train_Y, cv=10, scoring='neg_median_absolute_error')\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_reg.fit(kc_train, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "ensemble_time = 0\n",
    "\n",
    "for i in range(num_runs):\n",
    "    start = time.time()\n",
    "    stacked_pred = stacked_reg.predict(kc_test)\n",
    "    end = time.time()\n",
    "    ensemble_time += end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import math\n",
    "\n",
    "unlog_Y = np.exp(test_Y)\n",
    "unlog_pred = np.exp(stacked_pred)\n",
    "log_err = np.sum(np.log(unlog_Y) - np.log(unlog_pred))\n",
    "\n",
    "ensemble_dict ={\n",
    "    'name': 'ensemble',\n",
    "    'avg_pred':(ensemble_time/num_runs * 100000), \n",
    "    'single_pred':(ensemble_time/num_runs) / len(test_Y) * 100000, \n",
    "    'rmse': math.sqrt(mean_squared_error(unlog_Y, unlog_pred)),\n",
    "    'mae': mean_absolute_error(unlog_Y, unlog_pred),\n",
    "    'log_error': log_err\n",
    "}\n",
    "ensemble_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GBM Avg Predict Time(μs): \", ensemble_dict['avg_pred'])\n",
    "print(\"GBM Single Predict Time (μs): \", ensemble_dict['single_pred'])\n",
    "print(\"Ensemble RMSE: \", ensemble_dict['rmse'])\n",
    "print(\"Ensemble MAE: \", ensemble_dict['mae'])\n",
    "print(\"Ensemble Log Lerror: \", ensemble_dict['log_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.path.expanduser(\"~\")\n",
    "exec = os.path.join(home, \"LightGBM/lightgbm\")\n",
    "\n",
    "lgbm_alone = GBMRegressor(exec_path=exec, \n",
    "                    boosting_type='gbdt',\n",
    "                    feature_fraction_seed=SEED,\n",
    "                    bagging_seed=SEED,\n",
    "                    tree_learner='serial',\n",
    "                    metric='r2', #l2\n",
    "                    verbose=False,\n",
    "                    \n",
    "                    num_leaves=35,\n",
    "                    num_iterations=3800,#350 faster1\n",
    "                    learning_rate=0.01,#0.1 faster1\n",
    "                    max_bin=500, #255 faster1\n",
    "\n",
    "                    min_data_in_leaf=5,\n",
    "                    feature_fraction=1,\n",
    "\n",
    "                    bagging_fraction=1,\n",
    "                    bagging_freq=10,\n",
    "\n",
    "                    metric_freq=1,\n",
    "                    early_stopping_round=19\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_alone.fit(kc_train, train_Y)\n",
    "i = 0\n",
    "lgbm_time = 0\n",
    "num_runs = 100\n",
    "for i in range(num_runs):\n",
    "    start = time.time()\n",
    "    lgbm_pred = lgbm_alone.predict(kc_test)\n",
    "    end = time.time()\n",
    "    lgbm_time += end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlog_lgbm_pred = np.exp(lgbm_pred)\n",
    "\n",
    "lgbm_dict ={\n",
    "    'name': 'lgbm',\n",
    "    'avg_pred':(lgbm_time/num_runs * 100000), \n",
    "    'single_pred':(lgbm_time/num_runs) / len(test_Y) * 100000, \n",
    "    'rmse': math.sqrt(mean_squared_error(unlog_Y, unlog_lgbm_pred)),\n",
    "    'mae': mean_absolute_error(unlog_Y, unlog_lgbm_pred),\n",
    "    'log_error': np.sum(np.log(unlog_Y) - np.log(unlog_lgbm_pred))\n",
    "}\n",
    "\n",
    "print(\"LGBM Avg Predict Time (μs): \", lgbm_dict['avg_pred'])\n",
    "print(\"LGBM Single Predict Time (μs): \", lgbm_dict['single_pred'])\n",
    "print(\"LGBM RMSE: \", lgbm_dict['rmse'])\n",
    "print(\"LGBM MAE: \", lgbm_dict['mae'])\n",
    "print(\"LGBM Log-Error \", lgbm_dict['log_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_alone = xgb.XGBRegressor(\n",
    "    min_child_weight=5, \n",
    "    max_depth=3, \n",
    "    objective='reg:linear',\n",
    "    gamma=0,\n",
    "    reg_alpha=0.6,\n",
    "    reg_lambda=1,\n",
    "    learning_rate=0.1, \n",
    "    colsample_bytree=1.0, \n",
    "    seed=SEED, \n",
    "    n_estimators=2375, \n",
    "    subsample=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_alone.fit(kc_train, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "gbm_time = 0\n",
    "\n",
    "for i in range(num_runs):\n",
    "    start = time.time()\n",
    "    gbm_pred = gbm_alone.predict(kc_test)\n",
    "    end = time.time()\n",
    "    gbm_time += end-start\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlog_gbm_pred = np.exp(lgbm_pred)\n",
    "gbm_dict ={\n",
    "    'name': 'GBM',\n",
    "    'avg_pred':(gbm_time/num_runs * 100000), \n",
    "    'single_pred':(gbm_time/num_runs) / len(test_Y) * 100000, \n",
    "    'rmse': math.sqrt(mean_squared_error(unlog_Y, unlog_gbm_pred)),\n",
    "    'mae': mean_absolute_error(unlog_Y, unlog_gbm_pred),\n",
    "    'log_error': np.sum(np.log(unlog_Y) - np.log(unlog_gbm_pred))\n",
    "}\n",
    "\n",
    "print(\"GBM Avg Predict Time(μs): \", gbm_dict['avg_pred'])\n",
    "print(\"GBM Single Predict Time (μs): \", gbm_dict['single_pred'])\n",
    "print(\"GBM RMSE: \", gbm_dict['rmse'])\n",
    "print(\"GBM MAE: \", gbm_dict['mae'])\n",
    "print(\"GBM Log-Error: \", gbm_dict['log_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ensemble_dict, index=[0])\n",
    "df = df.append(lgbm_dict, ignore_index=True)\n",
    "df = df.append(gbm_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='avg_pred', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='single_pred', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='mae', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='rmse', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='log_error', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall RMSE and MAE scores of each respective models are relatively comparable, with the RMSE of the ensemble being slightly more efficient (approximately 1,000 dollars less). There is a tradeoff to be considered, in which the ensemble takes the most time (approximately the duration of the LGBM + GBM prediction times), but overall performs better on error metrics, especially as it faces a significant reduction in log loss error, from 16 down to 8.5. \n",
    "\n",
    "GBM seems to be the most lightweight of the model, only requiring 7 microseconds per prediction. It is important to consider the run-time use-cases for each model, if one is constructing a customer-facing api that utilizes one of these models for predictions. These prediction times are only relative -- though the stacked ensemble is the slowest, it is still relatively quick in the span of predicting, requiring only 32 microseconds per prediction. Additionally, if speed remains a problem, stacked ensembling allows distributed processing by fitting and predicting on different machines for a parallel approach.\n",
    "\n",
    "There remains an extensive amount of tuning and feature engineering available to improving the predictive capabilities of this model set, but these approaches were constrained due to cost and time. Additionally, the models need more data in order to converge further to an optimal result. Possible additional features were explored in the feature engineering section, which culminates in further leveraging the lat, long features in regards to coast distances, and overall proximity to amenities for a neighborhood rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
